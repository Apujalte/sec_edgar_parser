{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\36036\\OneDrive\\Github\\sec_edgar_parser\\sec_parse\n"
     ]
    }
   ],
   "source": [
    "cd sec_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = EdgarDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.make_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df = pd.read_sql_table(DB_COMPANY_TABLE, db._db_eng)\n",
    "filing_info_df = pd.read_sql_table(DB_FILING_TABLE, db._db_eng, parse_dates=['period', 'filed'])\n",
    "filing_data_df = pd.read_sql_table(DB_FILING_DATA_TABLE, db._db_eng, parse_dates=['value_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_data_df = pd.merge(filing_data_df, filing_info_df, how='left')\n",
    "all_data_df = pd.merge(most_data_df, company_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0000008947-18-000045')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.session.query(distinct(FilingInfo.filing_accession)).filter(exists().where(FilingInfo.filing_accession == '0001193125-18-122816')).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = db.session.query(distinct(FilingInfo.filing_accession)).filter(exists().where(FilingInfo.filing_accession == '001193125-18-122816')).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = db.session.query(FilingInfo, CompanyInfo).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<db.FilingInfo at 0x1d54f6d67f0>, <db.CompanyInfo at 0x1d54f7eb390>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418134"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Union\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_filing_dfs(file_path, re_search_terms) -> Union[None, List[pd.DataFrame]]:\n",
    "    if not file_path:\n",
    "        return None\n",
    "\n",
    "    return_dfs = []\n",
    "\n",
    "    if file_path.split(\".\")[-1] == 'xls' or 'xlsx':\n",
    "        excel = pd.ExcelFile(file_path)\n",
    "\n",
    "        for sheet_name in excel.sheet_names:\n",
    "            if re.search(re_search_terms, sheet_name, flags=re.IGNORECASE):\n",
    "                return_dfs.append(pd.read_excel(excel, sheet_name, header=None).dropna(how='all'))\n",
    "\n",
    "    elif file_path.split(\".\")[-1] == 'csv':\n",
    "        df_csv = pd.read_csv(file_path, header=None).dropna(how='all')\n",
    "\n",
    "        header_vals_list = [str(item) for item in flatten(df_csv.iloc[:5, :].values.tolist())]\n",
    "        header_vals_string = ' '.join([str(val) for val in header_vals_list])\n",
    "\n",
    "        if not re.search(re_search_terms, header_vals_string):\n",
    "            return_dfs.append(None)\n",
    "        else:\n",
    "            return return_dfs.append(df_csv)\n",
    "\n",
    "    return return_dfs\n",
    "\n",
    "\n",
    "def _clean_data_file(df, re_search_filing_type):\n",
    "    if type(df) is None:\n",
    "        return None\n",
    "\n",
    "    header_vals_list = [str(item) for item in flatten(df.iloc[:5, :].values.tolist())]\n",
    "    header_vals_string = ' '.join([str(val) for val in header_vals_list])\n",
    "\n",
    "    # unit correction to 1 USD\n",
    "    if re.search('thousands|Thousands', header_vals_string):\n",
    "        unit_multiplier = 1000\n",
    "    elif re.search('millions|Millions', header_vals_string):\n",
    "        unit_multiplier = 1000000\n",
    "    elif re.search('billions|Billions', header_vals_string):\n",
    "        unit_multiplier = 1000000000\n",
    "    else:\n",
    "        unit_multiplier = 1\n",
    "\n",
    "    # confirm sheet type by looking at header values for relevant string pattern\n",
    "    if re.search(re_search_filing_type, header_vals_string, flags=re.IGNORECASE) is None:\n",
    "        return None\n",
    "\n",
    "    dropped_df = df.dropna()\n",
    "\n",
    "    cleaned_df = dropped_df.applymap(lambda x: str(x).replace('\\n', ' ').replace(\"'\", \"\").replace(\":\", \"\")\n",
    "                                     .replace('-', '').replace('*', '').replace('  ', ' ').strip().title())\n",
    "\n",
    "    for col in cleaned_df.columns[1:]:\n",
    "        cleaned_df.loc[1:, col] = cleaned_df.loc[1:, col].apply(scale_array_val, args=(unit_multiplier,))\n",
    "\n",
    "    final_df = cleaned_df.dropna()\n",
    "\n",
    "    return final_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "def scale_array_val(val, scale_val):\n",
    "    try:\n",
    "        return float(str(val).replace(',', ''))*scale_val\n",
    "    except (ValueError, IndexError):\n",
    "        if val == '':\n",
    "            return nan\n",
    "        else:\n",
    "            return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(deep_list):\n",
    "    return [item for sublist in deep_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = _build_filing_dfs(\"C:/Users/36036/sec_parse_data/xlsx_data/0001138978_0001493152-18-005063.xlsx\", re_search_terms=r'\\bstate.*?\\bope|\\bcond.*?\\bconso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Revenues', 2145919.0, 1834620.0, 4399656.0, 3652759.0],\n",
       "       ['Cost Of Revenues', 1307596.0, 1189908.0, 2715289.0, 2354021.0],\n",
       "       ['Gross Profit', 838323.0, 644712.0, 1684367.0, 1298738.0],\n",
       "       ['Selling Expenses', 30601.0, 8259.0, 68740.0, 18560.0],\n",
       "       ['General And Administrative Expenses', 1934479.0, 589378.0,\n",
       "        2914754.0, 1170242.0],\n",
       "       ['Total Operating Expenses', 1965080.0, 597637.0, 2983494.0,\n",
       "        1188802.0],\n",
       "       ['Income (Loss) From Operations', 1126757.0, 47075.0, 1299127.0,\n",
       "        109936.0],\n",
       "       ['Interest Income', 160.0, 11010.0, 211.0, 21988.0],\n",
       "       ['Interest Expense', 304132.0, 114617.0, 438285.0, 231705.0],\n",
       "       ['Total Other Income (Expense)', 303972.0, 103607.0, 438074.0,\n",
       "        209717.0],\n",
       "       ['Loss Before Income Taxes', 1430729.0, 56532.0, 1737201.0,\n",
       "        99781.0],\n",
       "       ['Net Loss', 1376513.0, 56532.0, 1737201.0, 99781.0],\n",
       "       ['Net Loss Attributed To Noncontrolling Interest', 1956.0, 2764.0,\n",
       "        5356.0, 4491.0],\n",
       "       ['Net Loss Attributed To Novo Integrated Sciences, Inc.',\n",
       "        1374557.0, 53768.0, 1731845.0, 95290.0],\n",
       "       ['Net Loss', 1376513.0, 56532.0, 1737201.0, 99781.0],\n",
       "       ['Foreign Currency Translation Gain (Loss)', 211528.0, 94248.0,\n",
       "        87341.0, 66895.0],\n",
       "       ['Comprehensive Loss', 1588041.0, 150780.0, 1824542.0, 32886.0],\n",
       "       ['Weighted Average Common Shares Outstanding Basic And Diluted',\n",
       "        206091162.0, 167797406.0, 203953457.0, 167797406.0],\n",
       "       ['Net Loss Per Common Share Basic And Diluted', 0.01, 0.0, 0.01,\n",
       "        0.0]], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_clean_data_file(dfs[2], re_search_filing_type=r'condensed consolidated statements of operations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pd.ExcelFile(\"C:/Users/36036/sec_parse_data/xlsx_data/0001138978_0001493152-18-005063.xlsx\")\n",
    "for sheet_name in excel.sheet_names:\n",
    "    if re.search(r'\\bstate.*?\\bope', sheet_name, flags=re.I):\n",
    "        print(sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Condensed Consolidated Statements of Operation...</td>\n",
       "      <td>3 Months Ended</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 Months Ended</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Feb. 28, 2018</td>\n",
       "      <td>Feb. 28, 2017</td>\n",
       "      <td>Feb. 28, 2018</td>\n",
       "      <td>Feb. 28, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Income Statement [Abstract]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revenues</td>\n",
       "      <td>2145919</td>\n",
       "      <td>1834620</td>\n",
       "      <td>4399656</td>\n",
       "      <td>3652759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cost of revenues</td>\n",
       "      <td>1307596</td>\n",
       "      <td>1189908</td>\n",
       "      <td>2715289</td>\n",
       "      <td>2354021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0               1  \\\n",
       "0  Condensed Consolidated Statements of Operation...  3 Months Ended   \n",
       "1                                                NaN   Feb. 28, 2018   \n",
       "2                        Income Statement [Abstract]             NaN   \n",
       "3                                           Revenues         2145919   \n",
       "4                                   Cost of revenues         1307596   \n",
       "\n",
       "               2               3              4  \n",
       "0            NaN  6 Months Ended            NaN  \n",
       "1  Feb. 28, 2017   Feb. 28, 2018  Feb. 28, 2017  \n",
       "2            NaN             NaN            NaN  \n",
       "3        1834620         4399656        3652759  \n",
       "4        1189908         2715289        2354021  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_array_val(dropped_df.loc[1,1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[['Nan' 2018.0 2017.0 2018.0 2017.0]\n",
      " ['Revenues' 2145919.0 1834620.0 4399656.0 3652759.0]\n",
      " ['Cost Of Revenues' 1307596.0 1189908.0 2715289.0 2354021.0]\n",
      " ['Gross Profit' 838323.0 644712.0 1684367.0 1298738.0]\n",
      " ['Selling Expenses' 30601.0 8259.0 68740.0 18560.0]\n",
      " ['General And Administrative Expenses' 1934479.0 589378.0 2914754.0\n",
      "  1170242.0]\n",
      " ['Total Operating Expenses' 1965080.0 597637.0 2983494.0 1188802.0]\n",
      " ['Income (Loss) From Operations' 1126757.0 47075.0 1299127.0 109936.0]\n",
      " ['Interest Income' 160.0 11010.0 211.0 21988.0]\n",
      " ['Interest Expense' 304132.0 114617.0 438285.0 231705.0]\n",
      " ['Total Other Income (Expense)' 303972.0 103607.0 438074.0 209717.0]\n",
      " ['Loss Before Income Taxes' 1430729.0 56532.0 1737201.0 99781.0]\n",
      " ['Net Loss' 1376513.0 56532.0 1737201.0 99781.0]\n",
      " ['Net Loss Attributed To Noncontrolling Interest' 1956.0 2764.0 5356.0\n",
      "  4491.0]\n",
      " ['Net Loss Attributed To Novo Integrated Sciences, Inc.' 1374557.0\n",
      "  53768.0 1731845.0 95290.0]\n",
      " ['Net Loss' 1376513.0 56532.0 1737201.0 99781.0]\n",
      " ['Foreign Currency Translation Gain (Loss)' 211528.0 94248.0 87341.0\n",
      "  66895.0]\n",
      " ['Comprehensive Loss' 1588041.0 150780.0 1824542.0 32886.0]\n",
      " ['Weighted Average Common Shares Outstanding Basic And Diluted'\n",
      "  206091162.0 167797406.0 203953457.0 167797406.0]\n",
      " ['Net Loss Per Common Share Basic And Diluted' 0.01 0.0 0.01 0.0]]\n"
     ]
    }
   ],
   "source": [
    "df = dfs[2]\n",
    "\n",
    "header_vals_list = [str(item) for item in flatten(dfs[2].iloc[:5, :].values.tolist())]\n",
    "header_vals_string = ' '.join([str(val) for val in header_vals_list])\n",
    "\n",
    "# unit correction to 1 USD\n",
    "if re.search('thousands|Thousands', header_vals_string):\n",
    "    unit_multiplier = 1000\n",
    "elif re.search('millions|Millions', header_vals_string):\n",
    "    unit_multiplier = 1000000\n",
    "elif re.search('billions|Billions', header_vals_string):\n",
    "    unit_multiplier = 1000000000\n",
    "else:\n",
    "    unit_multiplier = 1\n",
    "\n",
    "# confirm sheet type by looking at header values for relevant string pattern\n",
    "if re.search(r'operations', header_vals_string, flags=re.I) is None:\n",
    "    print('None')\n",
    "    \n",
    "if re.search(r'12 months', header_vals_string, flags=re.I) is None:\n",
    "    print('None')\n",
    "    \n",
    "dropped_df = df.dropna(how='any', subset=df.columns[1:])\n",
    "\n",
    "cleaned_df = dropped_df.applymap(lambda x: str(x).replace('\\n', ' ').replace(\"'\", \"\").replace(\":\", \"\")\n",
    "                                 .replace('-', '').replace('*', '').replace('  ', ' ').strip().title())\n",
    "\n",
    "for col in cleaned_df.columns[1:]:\n",
    "    cleaned_df.loc[1:, col] = cleaned_df.loc[1:, col].apply(scale_array_val, args=(1,))\n",
    "\n",
    "final_df = cleaned_df.dropna()\n",
    "\n",
    "print(final_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=[0], keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
